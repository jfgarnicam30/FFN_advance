## Different files
As it has been described on the previous READMEs, the FFN algorithm is formed by several parts such as  data preparation, training process and  inference. The Parallel2 folder contains all the inputs and ouputs of each part. Below, you will find an explanation and several notes regarding to how to get the different inputs and how the outputs should look.

### Data preparation
Let us say that the training process needs three steps to be carried out. These are `compute_partitions.py`, `build_coordinates.py` and `train.py`. If read the main README on the FFN repository you will realize the next requirements by each stage:

**compute_partitions**: It requires a `.hdf5` file with the groundtruth of the data with which the training process will be done. To create this file, check the jupyter notebook called `create_hdf5_files.ipynb`. This notebook contains several scripts to create .hdf5 files. The description of these scripts is in the same notebook. Keep in mind next important factors:

- The groundtruth background must be white while the segmentation areas must be black (or in a gray-scale, if you have several objects).
- Data type of the images in the groundtruth must be uint8.
- The name of the dictionary that contains the groundtruth data set should be called `stack` (to keep concordance with the FFN data names).

compute_partitions do not take too much time running, approximately 50 minutes to run on the full data set (24 Gb spited into 192 sub-volumes). The output of this script is a `.h5` file . In our case, we got 192 `.h5` files one per each grundtruth file. To launch 192 groundtruth files through `compute_partitions.py` script, there are two scripts, `jobscript_compute_partitions.sh` which function is establishing the requirements to IBEX and call the second script `script_compute.py`. This last script performs the invocation of `compute_partitions.py` on **all the groundtruth files.**

**build_coordinates:** It requires a Tensorflow vector with coordinates which is provided by `compute_partitions.py`. Therefore, the `.h5` file from `compute_partitions.py` will be the input of `biuld_coordinates.py`.  In our case, this script took around of 7 days running through 32 sub-volumes. This means that this stage (stage 2) is the most time consuming.

**train**: It requires three inputs, groundtruth files, grayscale-maps and `build_coordinates.py` output. The ouput of this script is a model with the coefficients that contain the most relevant information of the training. The  main recommendations for this step are:

- The shape of groundtruth and grayscale-maps must be the same.
- `train.py` was coded to take a previous model (if it exists) and add it the new information of the current training process.
- The original version of this code was modified in order to get an output. Then, if want to get the model (output) in a different path, please check the explanation related to this written on the main README.
- The model obtained from the training of all of our data was saved on the path: `/var/remote/projects/epfl/data/KB-E0010/FFN_model`. 

## Inference
In order to run the inference you need the file over which you want to get the semgentation. This one must be a `.hdf5` file, ant the name of the dataset into should be `stack`. Be careful on indicating the right path where the model was stored. There are few recommendations related this step:
- Check the `jobscript_inference.sh`, it contains the script to run the segmentation.
- Modify the `.txt` file referred on `jobscript_inference.sh` which contains the parameters for the segmentation.
- Watch out! Sometimes the `run_inference.py` script does not show a notification of work finished. Without this notification IBEX is not able to finish our job and it continues running. So, it is recommendable check the `.err` file generated by IBEX in order to check the advance of the program, if after 2 hours the program is stack in a last message as `Executor shutdown complete.`, cancel the program on IBEX, this message indicates that the program is finished.

At the final part  on the README of the FFN, there is a short explanation about how to get the segmented images from FFN algorithm. However, that code does not work. Run the jupyter notebook called `own_segmentator.ipynb` to get the segmented images, and read carefully the comments on this  notebook.
